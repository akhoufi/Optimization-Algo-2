\providecommand{\bbobECDFslegend}[1]{
Bootstrapped empirical cumulative distribution of the number of objective function evaluations divided by dimension (FEvals/DIM) for $51$ targets with target precision in $10^{[-8..2]}$ for all functions and subgroups in #1-D. The ``best 2009'' line corresponds to the best \aRT\ observed during BBOB 2009 for each selected target.
}
\providecommand{\bbobppfigslegend}[1]{
Average running time (\aRT\ in number of $f$-evaluations
                    as $\log_{10}$ value), divided by dimension for target function value $10^{-8}$
                    versus dimension. Slanted grid lines indicate quadratic scaling with the dimension. Different symbols correspond to different algorithms given in the legend of #1. Light symbols give the maximum number of function evaluations from the longest trial divided by dimension. Black stars indicate a statistically better result compared to all other algorithms with $p<0.01$ and Bonferroni correction number of dimensions (six).  
Legend: 
{\color{NavyBlue}$\circ$}: \algorithmA
, {\color{Magenta}$\diamondsuit$}: \algorithmB
, {\color{Orange}$\star$}: \algorithmC
}
\providecommand{\bbobpptablesmanylegend}[2]{%
        Average running time (\aRT\ in number of function 
        evaluations) divided by the respective best \aRT\ measured during BBOB-2009 in
        #1.
        The \aRT\ and in braces, as dispersion measure, the half difference between 
        10 and 90\%-tile of bootstrapped run lengths appear for each algorithm and 
        %
        target, the corresponding best \aRT\
        in the first row. The different target \Df-values are shown in the top row.
        \#succ is the number of trials that reached the (final) target
        $\fopt + 10^{-8}$.
        %
        The median number of conducted function evaluations is additionally given in 
        \textit{italics}, if the target in the last column was never reached. 
        Entries, succeeded by a star, are statistically significantly better (according to
        the rank-sum test) when compared to all other algorithms of the table, with
        $p = 0.05$ or $p = 10^{-k}$ when the number $k$ following the star is larger
        than 1, with Bonferroni correction of #2. A $\downarrow$ indicates the same tested against the best
        algorithm of BBOB-2009. Best results are printed in bold.
        }
\providecommand{\algorithmA}{ex-100000}
\providecommand{\algorithmB}{BFGS}
\providecommand{\algorithmC}{budget50000}
\providecommand{\algorithmA}{ex-100000}
\providecommand{\algorithmB}{BFGS}
\providecommand{\algorithmC}{BIPOP-CMA-ES}
\providecommand{\algorithmD}{budget50000}
\providecommand{\algname}{ex-100000{}}
\providecommand{\algfolder}{exdata-100000/}
\providecommand{\bbobecdfcaptionallgroups}{
Empirical cumulative distribution of simulated (bootstrapped) runtimes, measured in number
         of objective function evaluations, divided by dimension (FEvals/DIM) for the $51$ targets $10^{[-8..2]}$ for all function groups and all dimensions. The aggregation over all 55 functions is shown in the last plot.
}
\providecommand{\bbobecdfcaptionsinglefcts}{
Empirical cumulative distribution of simulated (bootstrapped) runtimes in number
         of objective function evaluations divided by dimension (FEvals/DIM) for the $51$ targets $10^{[-8..2]}$ for functions $f_1$ to $f_{16}$ and all dimensions. 
}
\providecommand{\bbobpptablecaption}[1]{
%
        Average running time (\aRT\ in number of function 
        evaluations) divided by the best \aRT\ measured during BBOB-2009. The \aRT\ 
        and in braces, as dispersion measure, the half difference between 90 and 
        10\%-tile of bootstrapped run lengths appear in the second row of each cell,  
        the best \aRT\
        %
        in the first. The different target \Df-values are shown in the top row. 
        \#succ is the number of trials that reached the (final) target $\fopt + 10^{-8}$.
        %
        The median number of conducted function evaluations is additionally given in 
        \textit{italics}, if the target in the last column was never reached. 
        \textbf{Bold} entries are statistically significantly better (according to
        the rank-sum test) compared to the best algorithm in BBOB-2009, with
        $p = 0.05$ or $p = 10^{-k}$ when the number $k > 1$ is following the
        $\downarrow$ symbol, with Bonferroni correction by the number of
        functions.
        
}
\providecommand{\bbobppfigdimlegend}[1]{
%
        Scaling of runtime to reach $\fopt+10^{\#}$ with dimension;
        runtime is measured in number of $f$-evaluations and $\#$ is given in the legend;
        Lines: average runtime (\aRT);
        Cross (+): median runtime of successful runs to reach the most difficult
        target that was reached at least once (but not always);
        Cross ({\color{red}$\times$}): maximum number of
        $f$-evaluations in any trial. Notched
        boxes: interquartile range with median of simulated runs;
        % to reach $\fopt+10^{\#}$.
        %
        % Colors represent different target values. 
        All values are divided by dimension and 
        plotted as $\log_{10}$ values versus dimension. %
        %
        % Shown are $\Df = 10^{\{10, 1, 0.1, 0.01, 1e-3, 1e-5, 1e-8\}}$.  
        Numbers above \aRT-symbols (if appearing) indicate the number of trials
        reaching the respective target. The light thick line with
        diamonds indicates the respective best result from BBOB-2009 for
        $\Df=10^{-8}$. Horizontal lines mean linear scaling, slanted
        grid lines depict quadratic scaling.  
        
}
\providecommand{\bbobpprldistrlegend}[1]{
%
         Empirical cumulative distribution functions (ECDF), plotting the fraction of
         trials with an outcome not larger than the respective value on the $x$-axis.
         #1%
         Left subplots: ECDF of the number of function evaluations (FEvals) divided by search space dimension $D$,
         to fall below $\fopt+\Df$ with $\Df=10^{k}$, where $k$ is the first value in the legend.
         The thick red line represents the most difficult target value $\fopt+10^{-8}$. %
         Legends indicate for each target the number of functions that were solved in at
         least one trial within the displayed budget. %
         Right subplots: ECDF of the
         best achieved $\Df$
         for running times of $0.5D, 1.2D, 3D, 10D, 100D, 1000D,\dots$
         function evaluations
         (from right to left cycling cyan-magenta-black\dots) and final $\Df$-value (red),
         where \Df\ and \textsf{Df} denote the difference to the optimal function value. Light brown lines in the background show ECDFs for the most difficult target of all
         algorithms benchmarked during BBOB-2009.
}
\providecommand{\bbobloglossfigurecaption}[1]{
%
        \aRT\ loss ratios (see Figure~\ref{tab:aRTloss} for details).
        Each cross ({\color{blue}$+$}) represents a single function, the line
        is the geometric mean.
        
}
\providecommand{\bbobloglosstablecaption}[1]{
%
        \aRT\ loss ratio versus the budget in number of $f$-evaluations
        divided by dimension.
        For each given budget \FEvals, the target value \ftarget\ is computed
        as the best target $f$-value reached within the
        budget by the given algorithm.
        Shown is then the \aRT\ to reach \ftarget\ for the given algorithm
        or the budget, if the GECCO-BBOB-2009 best algorithm
        reached a better target within the budget,
        divided by the best \aRT\
        seen in GECCO-BBOB-2009 to reach \ftarget.
        Line: geometric mean. Box-Whisker error bar: 25-75\%-ile with median
        (box), 10-90\%-ile (caps), and minimum and maximum \aRT\ loss ratio
        (points). The vertical line gives the maximal number of function evaluations
        in a single trial in this function subset. See also
        Figure~\ref{fig:aRTlogloss} for results on each function subgroup.
        
}
\providecommand{\algname}{GA-MULTIOBJ-NSGA-II{}}
\providecommand{\algfolder}{GA-MULTIOBJ-NSGA-II/}
\providecommand{\bbobecdfcaptionallgroups}{
Empirical cumulative distribution of simulated (bootstrapped) runtimes, measured in number
         of objective function evaluations, divided by dimension (FEvals/DIM) for the $58$ targets $\{-10^{-4}, -10^{-4.2}, $ $-10^{-4.4}, -10^{-4.6}, -10^{-4.8}, -10^{-5}, 0, 10^{-5}, 10^{-4.9}, 10^{-4.8}, \dots, 10^{-0.1}, 10^0\}$ for all function groups and all dimensions. The aggregation over all 55 functions is shown in the last plot.
}
\providecommand{\bbobecdfcaptionsinglefcts}{
Empirical cumulative distribution of simulated (bootstrapped) runtimes in number
         of objective function evaluations divided by dimension (FEvals/DIM) for the $58$ targets $\{-10^{-4}, -10^{-4.2}, $ $-10^{-4.4}, -10^{-4.6}, -10^{-4.8}, -10^{-5}, 0, 10^{-5}, 10^{-4.9}, 10^{-4.8}, \dots, 10^{-0.1}, 10^0\}$ for functions $f_1$ to $f_{16}$ and all dimensions. 
}
\providecommand{\bbobpptablecaption}[1]{
%
                Average runtime (\aRT) to reach given targets, measured
                in number of function evaluations. For each function, the \aRT\ 
                and, in braces as dispersion measure, the half difference between 10 and 
                90\%-tile of (bootstrapped) runtimes is shown for the different
                target \Df-values as shown in the top row. 
                \#succ is the number of trials that reached the last target 
                $\hvref + 10^{-5}$.
                The median number of conducted function evaluations is additionally given in 
                \textit{italics}, if the target in the last column was never reached. 
                
}
\providecommand{\bbobppfigdimlegend}[1]{
%
        Scaling of runtime to reach $\hvref+10^{\#}$ with dimension;
        runtime is measured in number of $f$-evaluations and $\#$ is given in the legend;
        Lines: average runtime (\aRT);
        Cross (+): median runtime of successful runs to reach the most difficult
        target that was reached at least once (but not always);
        Cross ({\color{red}$\times$}): maximum number of
        $f$-evaluations in any trial. Notched
        boxes: interquartile range with median of simulated runs;
        % to reach $\hvref+10^{\#}$.
        %
        % Colors represent different target values. 
        All values are divided by dimension and 
        plotted as $\log_{10}$ values versus dimension. %
        %
        % Shown are $\Df = 10^{\{0.1, 0.01, 1e-3, 1e-4, 1e-5\}}$.  
        Numbers above \aRT-symbols (if appearing) indicate the number of trials
        reaching the respective target. Horizontal lines mean linear scaling, slanted
        grid lines depict quadratic scaling.  
        
}
\providecommand{\bbobpprldistrlegend}[1]{
%
         Empirical cumulative distribution functions (ECDF), plotting the fraction of
         trials with an outcome not larger than the respective value on the $x$-axis.
         #1%
         Left subplots: ECDF of the number of function evaluations (FEvals) divided by search space dimension $D$,
         to fall below $\hvref+\Df$ with $\Df=10^{k}$, where $k$ is the first value in the legend.
         The thick red line represents the most difficult target value $\hvref+10^{-5}$. %
         Legends indicate for each target the number of functions that were solved in at
         least one trial within the displayed budget. %
         Right subplots: ECDF of the
         best achieved $\Df$
         for running times of $0.5D, 1.2D, 3D, 10D, 100D, 1000D,\dots$
         function evaluations
         (from right to left cycling cyan-magenta-black\dots) and final $\Df$-value (red),
         where \Df\ and \textsf{Df} denote the difference to the optimal function value. Shown are aggregations over functions where the single
         objectives are in the same BBOB function class, as indicated on the
         left side and the aggregation over all 55 functions in the last
         row.
}
\providecommand{\bbobloglossfigurecaption}[1]{
%
        \aRT\ loss ratios (see Figure~\ref{tab:aRTloss} for details).
        Each cross ({\color{blue}$+$}) represents a single function, the line
        is the geometric mean.
        
}
\providecommand{\bbobloglosstablecaption}[1]{
%
        \aRT\ loss ratio versus the budget in number of $f$-evaluations
        divided by dimension.
        For each given budget \FEvals, the target value \ftarget\ is computed
        as the best target $f$-value reached within the
        budget by the given algorithm.
        Shown is then the \aRT\ to reach \ftarget\ for the given algorithm
        or the budget, if the GECCO-BBOB-2009 best algorithm
        reached a better target within the budget,
        divided by the best \aRT\
        seen in GECCO-BBOB-2009 to reach \ftarget.
        Line: geometric mean. Box-Whisker error bar: 25-75\%-ile with median
        (box), 10-90\%-ile (caps), and minimum and maximum \aRT\ loss ratio
        (points). The vertical line gives the maximal number of function evaluations
        in a single trial in this function subset. See also
        Figure~\ref{fig:aRTlogloss} for results on each function subgroup.
        
}
\providecommand{\algname}{ex{}}
\providecommand{\algfolder}{exdata/}
\providecommand{\bbobecdfcaptionallgroups}{
Empirical cumulative distribution of simulated (bootstrapped) runtimes, measured in number
         of objective function evaluations, divided by dimension (FEvals/DIM) for the $51$ targets $10^{[-8..2]}$ for all function groups and all dimensions. The aggregation over all 55 functions is shown in the last plot.
}
\providecommand{\bbobecdfcaptionsinglefcts}{
Empirical cumulative distribution of simulated (bootstrapped) runtimes in number
         of objective function evaluations divided by dimension (FEvals/DIM) for the $51$ targets $10^{[-8..2]}$ for functions $f_1$ to $f_{16}$ and all dimensions. 
}
